# -*- coding: utf-8 -*-
"""Mask-Detection-Train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Shx5m5dFHZBNt3oO6WdKO0B4KN-0kD0d
"""

import torch
print(torch.__version__)

pip install xmltodict

import os
import cv2
import xmltodict
import numpy as np
import torch
import torchvision.transforms as tt
import torchvision.datasets
from torchvision.datasets import ImageFolder
from torch.utils.data.dataloader import DataLoader
import torch.nn.functional as F
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

#Mounting google drive to colab.

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/Kaggle

"""# Dataset Collection and Organization"""

#Adding all images to the list - 'images'

images = []
for dirname, _, filenames in os.walk('/content/gdrive/My Drive/Kaggle'):
  for file_path in filenames:
    extension = file_path[len(file_path) - 4:]
    if extension != '.xml':
      images.append(file_path)
del images[0:1]

#For the given image name, this function returns the path for that particular image and it's label.

def get_path(image_name):

    home_dir = '/content/gdrive/My Drive/Kaggle/'
    image_path = home_dir + 'images/' + image_name

    if image_name[-4:] == 'jpeg':
        label_name = image_name[:-5] + '.xml'
    else:
        label_name = image_name[:-4] + '.xml'

    label_path = home_dir + 'labels/' + label_name

    return  image_path, label_path

#Returns the coordinates and size of the bounding box around the faces.

def parse_xml(label_path):
    x = xmltodict.parse(open(label_path , 'rb'))
    item_list = x['annotation']['object']

    # when image has only one face
    if not isinstance(item_list, list):
        item_list = [item_list]

    result = []
    #when image has multiple faces
    for item in item_list:
        name = item['name']
        bndbox = [(int(item['bndbox']['xmin']), int(item['bndbox']['ymin'])),
                  (int(item['bndbox']['xmax']), int(item['bndbox']['ymax']))]
        result.append((name, bndbox))

    size = [int(x['annotation']['size']['width']),
            int(x['annotation']['size']['height'])]

    return result, size

#Crops the faces in the image using the bounding box coordinates and adds each one to a list with the corresponding label.

def get_image(image_name, bndbox=True):

    new_image = []

    image_path, label_path = get_path(image_name)
    bgr_image = cv2.imread(image_path)

    if bndbox:
        labels, size = parse_xml(label_path)

        for label in labels:
            name, bndbox = label

            small_image = bgr_image[bndbox[0][1]:bndbox[1][1], bndbox[0][0]:bndbox[1][0]]

            if name == 'good':
                label_num = 0
            elif name == 'bad':
                label_num = 1
            else:
                label_num = 2

            n_image = [small_image, label_num]

            new_image.append(n_image)

    return new_image

#Creates a separate directory for images of each label and adds each image to the corresponding folder.

def make_directory(dir_name):
  try:
      os.mkdir(dir_name)
  except FileExistsError:
    print("directory" + dir_name + "already exists")

main_dir = "train/"
label_0_dir = main_dir + "0/"
label_1_dir = main_dir + "1/"
label_2_dir = main_dir + "2/"

make_directory(main_dir)
make_directory(label_0_dir)
make_directory(label_1_dir)
make_directory(label_2_dir)

label_0_count = 0
label_1_count = 0
label_2_count = 0

for x in images:
  print(x)
  up_image = get_image(x)


  for im in up_image:
    label = im[1]
    image = im[0]

    if label == 0:
      cropped_image = str(label_0_count) + '.jpg'
      cv2.imwrite(label_0_dir + cropped_image, image)
      label_0_count += 1

    elif label == 1:
      cropped_image = str(label_1_count) + '.jpg'
      cv2.imwrite(label_1_dir + cropped_image, image)
      label_1_count += 1

    elif label == 2:
      cropped_image = str(label_2_count) + '.jpg'
      cv2.imwrite(label_2_dir + cropped_image, image)
      label_2_count += 1

filenames_label_0 = [f for f in os.listdir(label_0_dir) if os.path.isfile(os.path.join(label_0_dir, f))]
filenames_label_1 = [f for f in os.listdir(label_1_dir) if os.path.isfile(os.path.join(label_1_dir, f))]
filenames_label_2 = [f for f in os.listdir(label_2_dir) if os.path.isfile(os.path.join(label_2_dir, f))]

print(len(filenames_label_0) + len(filenames_label_1) + len(filenames_label_2) )

"""## **TRAINING THE MODEL**"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

model = torchvision.models.resnet50(pretrained=True)

model.fc = nn.Sequential(nn.Linear(2048, 1000),
                         nn.ReLU(),
                         nn.Dropout(),
                         nn.Linear(1000, 3))

model.to(device)

stats= ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
train_tfms = tt.Compose([tt.Resize((224, 224)),
                        tt.ToTensor(),
                        tt.Normalize(*stats)])

dataset = ImageFolder(main_dir, transform=train_tfms)

dataset_size = len(dataset)
val_size = int(dataset_size * 0.2)
train_size = dataset_size - val_size

train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])

BATCH_SIZE = 45

train_loader = torch.utils.data.DataLoader(train_set,
                                          batch_size=BATCH_SIZE,
                                          shuffle=False,
                                          pin_memory=True)


val_loader = torch.utils.data.DataLoader(val_set,
                                          batch_size=BATCH_SIZE,
                                          shuffle=False,
                                          pin_memory=True)

total_epoch = 20
learning_rate = 0.003
loss_fn = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

make_directory("models")
models_dir = "models/"

#For a given number of epochs, it trains the model and checks accuracy against the validation set.

i=0
train_loss=[]
val_loss=[]
for epoch in range(total_epoch):

    torch.manual_seed(2 + epoch)
    epoch_train_loss = 0
    count=0
    for X, y in train_loader:

        count += 1
        X, y = X.to(device), y.to(device)
        optimizer.zero_grad()
        result = model(X)
        loss = loss_fn(result, y)
        epoch_train_loss += loss.item()
        loss.backward()
        optimizer.step()

    train_loss.append(epoch_train_loss)


    epoch_val_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for X, y in val_loader:

            X, y = X.to(device), y.to(device)

            result = model(X)
            loss = loss_fn(result, y)
            epoch_val_loss += loss.item()
            _, maximum = torch.max(result.data, 1)
            total += y.size(0)
            correct += (maximum == y).sum().item()

        val_loss.append(epoch_val_loss)
    accuracy = correct/total

    print("Epoch:", epoch, ", Training Loss:", epoch_train_loss, ", Validation Loss:", epoch_val_loss, ", Accuracy: ", accuracy)

    #Finds the epoch with the least validation loss and saves the model

    if min(val_loss)==val_loss[-1]:
      best_epoch = epoch

      checkpoint = {"model":model,
                  "state_dict":model.state_dict(),
                  "optimizer":optimizer.state_dict()}

      torch.save(checkpoint, models_dir + '{}.pth'.format(epoch))

#Loads the specified model that was saved earlier

def load_checkpoint(filepath):
    checkpoint = torch.load(filepath)
    model = checkpoint['model']
    model.load_state_dict(checkpoint['state_dict'])
    for parameter in model.parameters():
        parameter.requires_grad = False

    return model.eval()

#filepath = models_dir + "5.pth"
filepath = models_dir + str(best_epoc) + ".pth"
loaded_model = load_checkpoint(filepath)

img, label = dataset[0]
xb = img.unsqueeze(0)
xb = xb.cuda()
yb = model(xb)
print(yb)

def predict_image(img, model):
    # Convert to a batch of 1
    xb = img.unsqueeze(0)
    xb = xb.to(device)
    # Get predictions from model
    yb = model(xb)
    # Pick index with highest probability
    _, preds  = torch.max(yb, dim=1)
    pre = preds.item()
    print(pre)
    # Retrieve the class label
    return dataset.classes[preds[0].item()]

img, label = dataset[3456]
plt.imshow(img.permute(1, 2, 0))
print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, loaded_model))
