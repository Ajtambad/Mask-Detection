{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask-Detection-Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0237ef8807e944cdb38fae82b8666ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bbfb54ce5a324fe5afc581152a43da0d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc8dc67451b34220ba57b3323af488f9",
              "IPY_MODEL_ffaf0b5a34a149578618fc4f4f6038c5"
            ]
          }
        },
        "bbfb54ce5a324fe5afc581152a43da0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc8dc67451b34220ba57b3323af488f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f867e472c6484fc7b37153c8c94f6333",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce8b46b7d333461ba8c281b71ecf5c97"
          }
        },
        "ffaf0b5a34a149578618fc4f4f6038c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca05cfd6752748c0987b02cfb195ebc9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [03:16&lt;00:00, 520kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f97dd02b1994c8a8547543338475316"
          }
        },
        "f867e472c6484fc7b37153c8c94f6333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce8b46b7d333461ba8c281b71ecf5c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca05cfd6752748c0987b02cfb195ebc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f97dd02b1994c8a8547543338475316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifuDi2iRkqGD",
        "colab_type": "text"
      },
      "source": [
        "Due to the lack of GPU on my local machine, I used Google Colab for this part of the code as it involves training the model with a ResNet-50 architecture.\n",
        "\n",
        "I then saved the model and tested it with real time data on my local machine. The code for this is in Mask-Detection-#2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBmOWUh7Gv_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abdd93dc-34dc-474b-b984-0634bc6e6a3d"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKnPm_3svp7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install xmltodict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWvv1bHb7huh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import xmltodict\n",
        "import numpy as np\n",
        "import torch \n",
        "import torchvision.transforms as tt\n",
        "import torchvision.datasets \n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQUlzsOEu0Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mounting google drive to colab.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Df_UgDCmw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aguWBeEkBppu",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Collection and Organization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikzODVHQ4mfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding all images to the list - 'images'\n",
        "\n",
        "images = []\n",
        "for dirname, _, filenames in os.walk('/content/gdrive/My Drive/Kaggle'):\n",
        "  for file_path in filenames:\n",
        "    extension = file_path[len(file_path) - 4:]\n",
        "    if extension != '.xml':\n",
        "      images.append(file_path)\n",
        "del images[0:1]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hotDQm-W8io-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For the given image name, this function returns the path for that particular image and it's label.\n",
        "\n",
        "def get_path(image_name):\n",
        "\n",
        "    home_dir = '/content/gdrive/My Drive/Kaggle/'\n",
        "    image_path = home_dir + 'images/' + image_name\n",
        "    \n",
        "    if image_name[-4:] == 'jpeg':\n",
        "        label_name = image_name[:-5] + '.xml'\n",
        "    else:\n",
        "        label_name = image_name[:-4] + '.xml'\n",
        "    \n",
        "    label_path = home_dir + 'labels/' + label_name\n",
        "    \n",
        "    return  image_path, label_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWNVnSuje3hI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Returns the coordinates and size of the bounding box around the faces.\n",
        "\n",
        "def parse_xml(label_path):\n",
        "    x = xmltodict.parse(open(label_path , 'rb'))\n",
        "    item_list = x['annotation']['object']\n",
        "    \n",
        "    # when image has only one face\n",
        "    if not isinstance(item_list, list):\n",
        "        item_list = [item_list]\n",
        "        \n",
        "    result = []\n",
        "    #when image has multiple faces\n",
        "    for item in item_list:\n",
        "        name = item['name']\n",
        "        bndbox = [(int(item['bndbox']['xmin']), int(item['bndbox']['ymin'])),\n",
        "                  (int(item['bndbox']['xmax']), int(item['bndbox']['ymax']))]       \n",
        "        result.append((name, bndbox))\n",
        "    \n",
        "    size = [int(x['annotation']['size']['width']), \n",
        "            int(x['annotation']['size']['height'])]\n",
        "    \n",
        "    return result, size\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgtTu4Tnhotq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Crops the faces in the image using the bounding box coordinates and adds each one to a list with the corresponding label.\n",
        "\n",
        "def get_image(image_name, bndbox=True):\n",
        "\n",
        "    new_image = []\n",
        "\n",
        "    image_path, label_path = get_path(image_name)\n",
        "    bgr_image = cv2.imread(image_path)\n",
        "\n",
        "    if bndbox:\n",
        "        labels, size = parse_xml(label_path)\n",
        "        \n",
        "        for label in labels:\n",
        "            name, bndbox = label\n",
        "\n",
        "            small_image = bgr_image[bndbox[0][1]:bndbox[1][1], bndbox[0][0]:bndbox[1][0]]\n",
        "            \n",
        "            if name == 'good':\n",
        "                label_num = 0\n",
        "            elif name == 'bad':\n",
        "                label_num = 1\n",
        "            else:\n",
        "                label_num = 2\n",
        "\n",
        "            n_image = [small_image, label_num]\n",
        "\n",
        "            new_image.append(n_image)\n",
        "    \n",
        "    return new_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mvRPciu9Yeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creates a separate directory for images of each label and adds each image to the corresponding folder.\n",
        "\n",
        "def make_directory(dir_name):\n",
        "  try:\n",
        "      os.mkdir(dir_name)\n",
        "  except FileExistsError:\n",
        "    print(\"directory\" + dir_name + \"already exists\")\n",
        "\n",
        "main_dir = \"train/\"\n",
        "label_0_dir = main_dir + \"0/\"\n",
        "label_1_dir = main_dir + \"1/\"\n",
        "label_2_dir = main_dir + \"2/\"\n",
        "\n",
        "make_directory(main_dir)\n",
        "make_directory(label_0_dir)\n",
        "make_directory(label_1_dir)\n",
        "make_directory(label_2_dir)\n",
        "\n",
        "label_0_count = 0\n",
        "label_1_count = 0\n",
        "label_2_count = 0\n",
        "\n",
        "for x in images:\n",
        "  print(x)\n",
        "  up_image = get_image(x)\n",
        "\n",
        "\n",
        "  for im in up_image:\n",
        "    label = im[1]\n",
        "    image = im[0]\n",
        "\n",
        "    if label == 0:\n",
        "      cropped_image = str(label_0_count) + '.jpg'\n",
        "      cv2.imwrite(label_0_dir + cropped_image, image)\n",
        "      label_0_count += 1\n",
        "\n",
        "    elif label == 1:\n",
        "      cropped_image = str(label_1_count) + '.jpg'\n",
        "      cv2.imwrite(label_1_dir + cropped_image, image)\n",
        "      label_1_count += 1\n",
        "\n",
        "    elif label == 2:\n",
        "      cropped_image = str(label_2_count) + '.jpg'\n",
        "      cv2.imwrite(label_2_dir + cropped_image, image)\n",
        "      label_2_count += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J91Y3w1fwPeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames_label_0 = [f for f in os.listdir(label_0_dir) if os.path.isfile(os.path.join(label_0_dir, f))] \n",
        "filenames_label_1 = [f for f in os.listdir(label_1_dir) if os.path.isfile(os.path.join(label_1_dir, f))] \n",
        "filenames_label_2 = [f for f in os.listdir(label_2_dir) if os.path.isfile(os.path.join(label_2_dir, f))]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDmIS1YbcSu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a1f3f14-5bb3-4eef-8e57-fa979218a604"
      },
      "source": [
        "print(len(filenames_label_0) + len(filenames_label_1) + len(filenames_label_2) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVlmrlXd31-l",
        "colab_type": "text"
      },
      "source": [
        "## **TRAINING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6ih96kUKQ_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ace32a6-41d3-468e-e3c0-1e959dd3d3d2"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZirKChgiVqhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0237ef8807e944cdb38fae82b8666ab8",
            "bbfb54ce5a324fe5afc581152a43da0d",
            "cc8dc67451b34220ba57b3323af488f9",
            "ffaf0b5a34a149578618fc4f4f6038c5",
            "f867e472c6484fc7b37153c8c94f6333",
            "ce8b46b7d333461ba8c281b71ecf5c97",
            "ca05cfd6752748c0987b02cfb195ebc9",
            "6f97dd02b1994c8a8547543338475316"
          ]
        },
        "outputId": "74f22f60-0e0d-47c4-a92a-d1f8c4c2840f"
      },
      "source": [
        "model = torchvision.models.resnet50(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0237ef8807e944cdb38fae82b8666ab8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp9_9SvD8iBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fc = nn.Sequential(nn.Linear(2048, 1000),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Dropout(),\n",
        "                         nn.Linear(1000, 3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLMQniXxKTQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix13m_W-2FAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats= ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "train_tfms = tt.Compose([tt.Resize((224, 224)),\n",
        "                        tt.ToTensor(),\n",
        "                        tt.Normalize(*stats)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2d8c-26RT3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = ImageFolder(main_dir, transform=train_tfms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJab9aVl2Dwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_size = len(dataset)\n",
        "val_size = int(dataset_size * 0.2)\n",
        "train_size = dataset_size - val_size\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbD5W28jFOkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 45\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=False,\n",
        "                                          pin_memory=True)\n",
        "                \n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_set,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=False,\n",
        "                                          pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1WII699cHJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_epoch = 20\n",
        "learning_rate = 0.003\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrmPZk3WILFu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c516738e-2730-4ff8-b09c-037867cc84b2"
      },
      "source": [
        "make_directory(\"models\")\n",
        "models_dir = \"models/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "directorymodelsalready exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idJDH_15EMD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For a given number of epochs, it trains the model and checks accuracy against the validation set.\n",
        "\n",
        "i=0\n",
        "train_loss=[]\n",
        "val_loss=[]\n",
        "for epoch in range(total_epoch):\n",
        "    \n",
        "    torch.manual_seed(2 + epoch)\n",
        "    epoch_train_loss = 0\n",
        "    count=0\n",
        "    for X, y in train_loader:\n",
        "        \n",
        "        count += 1\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        result = model(X)\n",
        "        loss = loss_fn(result, y)\n",
        "        epoch_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "    train_loss.append(epoch_train_loss)\n",
        "    \n",
        "    \n",
        "    epoch_val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "          \n",
        "            X, y = X.to(device), y.to(device)\n",
        "             \n",
        "            result = model(X)\n",
        "            loss = loss_fn(result, y)\n",
        "            epoch_val_loss += loss.item()\n",
        "            _, maximum = torch.max(result.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (maximum == y).sum().item()\n",
        "            \n",
        "        val_loss.append(epoch_val_loss)\n",
        "    accuracy = correct/total\n",
        "\n",
        "    print(\"Epoch:\", epoch, \", Training Loss:\", epoch_train_loss, \", Validation Loss:\", epoch_val_loss, \", Accuracy: \", accuracy)\n",
        "\n",
        "    #Finds the epoch with the least validation loss and saves the model\n",
        "\n",
        "    if min(val_loss)==val_loss[-1]:\n",
        "      best_epoch = epoch\n",
        "\n",
        "      checkpoint = {\"model\":model,\n",
        "                  \"state_dict\":model.state_dict(),\n",
        "                  \"optimizer\":optimizer.state_dict()}\n",
        "\n",
        "      torch.save(checkpoint, models_dir + '{}.pth'.format(epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPXPNBjdwM0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loads the specified model that was saved earlier\n",
        "\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "    \n",
        "    return model.eval()\n",
        "\n",
        "#filepath = models_dir + \"5.pth\"\n",
        "filepath = models_dir + str(best_epoc) + \".pth\"\n",
        "loaded_model = load_checkpoint(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHkk9qozJY1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b957a846-4978-424f-ea15-69a9c160cfce"
      },
      "source": [
        "img, label = dataset[0]\n",
        "xb = img.unsqueeze(0)\n",
        "xb = xb.cuda()\n",
        "yb = model(xb)\n",
        "print(yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0349,  0.0049,  0.1385]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_voWXpOLJDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_image(img, model):\n",
        "    # Convert to a batch of 1\n",
        "    xb = img.unsqueeze(0)\n",
        "    xb = xb.to(device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    pre = preds.item()\n",
        "    print(pre)\n",
        "    # Retrieve the class label\n",
        "    return dataset.classes[preds[0].item()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95gAtaOjLLih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img, label = dataset[3456]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, loaded_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LukQjObCU54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}